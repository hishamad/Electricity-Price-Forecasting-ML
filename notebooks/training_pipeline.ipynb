{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hopsworks\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'functions')))\n",
    "import util\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'model')))\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-03 14:32:13,390 INFO: Initializing external client\n",
      "2025-01-03 14:32:13,391 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-03 14:32:14,648 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1164449\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "proj = hopsworks.login()\n",
    "fs = proj.get_feature_store(\"KTH_ID2223\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_prices_fg = fs.get_feature_group(\n",
    "    name='el_prices',\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")\n",
    "power_fg = fs.get_feature_group(\n",
    "    name='power',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.02s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-23 00:00:00+00:00</td>\n",
       "      <td>1.662196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-20 00:00:00+00:00</td>\n",
       "      <td>0.535002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-27 00:00:00+00:00</td>\n",
       "      <td>0.064113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-15 00:00:00+00:00</td>\n",
       "      <td>0.975358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-01 00:00:00+00:00</td>\n",
       "      <td>0.655705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-27 00:00:00+00:00</td>\n",
       "      <td>0.381928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-26 00:00:00+00:00</td>\n",
       "      <td>1.101363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-06-02 00:00:00+00:00</td>\n",
       "      <td>0.097737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-03-22 00:00:00+00:00</td>\n",
       "      <td>0.488279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-09-04 00:00:00+00:00</td>\n",
       "      <td>0.209347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date     price\n",
       "0 2023-01-23 00:00:00+00:00  1.662196\n",
       "1 2023-12-20 00:00:00+00:00  0.535002\n",
       "2 2023-05-27 00:00:00+00:00  0.064113\n",
       "3 2023-03-15 00:00:00+00:00  0.975358\n",
       "4 2022-11-01 00:00:00+00:00  0.655705\n",
       "5 2023-07-27 00:00:00+00:00  0.381928\n",
       "6 2023-01-26 00:00:00+00:00  1.101363\n",
       "7 2024-06-02 00:00:00+00:00  0.097737\n",
       "8 2023-03-22 00:00:00+00:00  0.488279\n",
       "9 2024-09-04 00:00:00+00:00  0.209347"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el_prices_fg.show(10)\n",
    "# weather_fg.show(10)\n",
    "# power_fg.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.80s) \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.68s) \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.67s) \n"
     ]
    }
   ],
   "source": [
    "weather_df = weather_fg.read()\n",
    "power_df = power_fg.read()\n",
    "el_prices_df = el_prices_fg.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = (\n",
    "    weather_df\n",
    "    .merge(power_df, on=\"date\", how=\"inner\")\n",
    "    .merge(el_prices_df, on=\"date\", how=\"inner\")\n",
    ")\n",
    "\n",
    "merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
    "merged_df = merged_df.sort_values(by=\"date\").reset_index(drop=True)\n",
    "\n",
    "dates = merged_df['date']\n",
    "features = merged_df.drop(columns=['date', 'price']).iloc[:-1]\n",
    "target = merged_df['price'].iloc[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "      <th>sunshine_duration</th>\n",
       "      <th>hydro_mw</th>\n",
       "      <th>nuclear_mw</th>\n",
       "      <th>other_mw</th>\n",
       "      <th>wind_mw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.653366</td>\n",
       "      <td>0.036923</td>\n",
       "      <td>0.261506</td>\n",
       "      <td>0.584641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.675887</td>\n",
       "      <td>0.706623</td>\n",
       "      <td>0.369720</td>\n",
       "      <td>0.208402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.676117</td>\n",
       "      <td>0.027692</td>\n",
       "      <td>0.264039</td>\n",
       "      <td>0.521290</td>\n",
       "      <td>0.329079</td>\n",
       "      <td>0.588815</td>\n",
       "      <td>0.704314</td>\n",
       "      <td>0.371038</td>\n",
       "      <td>0.331940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.631770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315841</td>\n",
       "      <td>0.536078</td>\n",
       "      <td>0.423145</td>\n",
       "      <td>0.582232</td>\n",
       "      <td>0.703846</td>\n",
       "      <td>0.390193</td>\n",
       "      <td>0.380272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.642915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550507</td>\n",
       "      <td>0.403879</td>\n",
       "      <td>0.378280</td>\n",
       "      <td>0.463541</td>\n",
       "      <td>0.705697</td>\n",
       "      <td>0.363238</td>\n",
       "      <td>0.457186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.625419</td>\n",
       "      <td>0.172308</td>\n",
       "      <td>0.474518</td>\n",
       "      <td>0.439128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.459842</td>\n",
       "      <td>0.706593</td>\n",
       "      <td>0.303004</td>\n",
       "      <td>0.489668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>0.437348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622481</td>\n",
       "      <td>0.793877</td>\n",
       "      <td>0.225706</td>\n",
       "      <td>0.591902</td>\n",
       "      <td>0.735926</td>\n",
       "      <td>0.340284</td>\n",
       "      <td>0.672421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>0.443700</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.571780</td>\n",
       "      <td>0.519946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.664265</td>\n",
       "      <td>0.735169</td>\n",
       "      <td>0.275513</td>\n",
       "      <td>0.616507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>0.525927</td>\n",
       "      <td>0.064615</td>\n",
       "      <td>0.636439</td>\n",
       "      <td>0.656699</td>\n",
       "      <td>0.024690</td>\n",
       "      <td>0.631070</td>\n",
       "      <td>0.735428</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>0.548422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>0.413558</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.418330</td>\n",
       "      <td>0.788535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692749</td>\n",
       "      <td>0.736244</td>\n",
       "      <td>0.228868</td>\n",
       "      <td>0.635597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>0.410105</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>0.451865</td>\n",
       "      <td>0.006552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611054</td>\n",
       "      <td>0.735896</td>\n",
       "      <td>0.164789</td>\n",
       "      <td>0.519209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>782 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     temperature_2m_mean  precipitation_sum  wind_speed_10m_max  \\\n",
       "0               0.653366           0.036923            0.261506   \n",
       "1               0.676117           0.027692            0.264039   \n",
       "2               0.631770           0.000000            0.315841   \n",
       "3               0.642915           0.000000            0.550507   \n",
       "4               0.625419           0.172308            0.474518   \n",
       "..                   ...                ...                 ...   \n",
       "777             0.437348           0.000000            0.622481   \n",
       "778             0.443700           0.160000            0.571780   \n",
       "779             0.525927           0.064615            0.636439   \n",
       "780             0.413558           0.006154            0.418330   \n",
       "781             0.410105           0.323077            0.451865   \n",
       "\n",
       "     wind_direction_10m_dominant  sunshine_duration  hydro_mw  nuclear_mw  \\\n",
       "0                       0.584641           0.000000  0.675887    0.706623   \n",
       "1                       0.521290           0.329079  0.588815    0.704314   \n",
       "2                       0.536078           0.423145  0.582232    0.703846   \n",
       "3                       0.403879           0.378280  0.463541    0.705697   \n",
       "4                       0.439128           0.000000  0.459842    0.706593   \n",
       "..                           ...                ...       ...         ...   \n",
       "777                     0.793877           0.225706  0.591902    0.735926   \n",
       "778                     0.519946           0.000000  0.664265    0.735169   \n",
       "779                     0.656699           0.024690  0.631070    0.735428   \n",
       "780                     0.788535           0.000000  0.692749    0.736244   \n",
       "781                     0.006552           0.000000  0.611054    0.735896   \n",
       "\n",
       "     other_mw   wind_mw  \n",
       "0    0.369720  0.208402  \n",
       "1    0.371038  0.331940  \n",
       "2    0.390193  0.380272  \n",
       "3    0.363238  0.457186  \n",
       "4    0.303004  0.489668  \n",
       "..        ...       ...  \n",
       "777  0.340284  0.672421  \n",
       "778  0.275513  0.616507  \n",
       "779  0.172500  0.548422  \n",
       "780  0.228868  0.635597  \n",
       "781  0.164789  0.519209  \n",
       "\n",
       "[782 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# normalizer = MinMaxScaler()\n",
    "# normalized_continuous_features = normalizer.fit_transform(features)\n",
    "# normalized_features_df = pd.DataFrame(normalized_continuous_features, columns=features.columns)\n",
    "# normalized_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      0.607735\n",
       "2      0.550615\n",
       "3      0.292413\n",
       "4      0.422040\n",
       "5      0.351532\n",
       "         ...   \n",
       "778    0.384965\n",
       "779    0.230300\n",
       "780    0.324242\n",
       "781    0.075346\n",
       "782    0.925848\n",
       "Name: price, Length: 782, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Lagged Prices for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "      <th>sunshine_duration</th>\n",
       "      <th>hydro_mw</th>\n",
       "      <th>nuclear_mw</th>\n",
       "      <th>other_mw</th>\n",
       "      <th>wind_mw</th>\n",
       "      <th>price_lag_1</th>\n",
       "      <th>price_lag_2</th>\n",
       "      <th>price_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.792083</td>\n",
       "      <td>1.2</td>\n",
       "      <td>13.202726</td>\n",
       "      <td>210.351074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8805.291667</td>\n",
       "      <td>5699.208333</td>\n",
       "      <td>897.958333</td>\n",
       "      <td>2831.708333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.612916</td>\n",
       "      <td>0.9</td>\n",
       "      <td>13.276144</td>\n",
       "      <td>187.686081</td>\n",
       "      <td>19597.978516</td>\n",
       "      <td>7981.458333</td>\n",
       "      <td>5689.541667</td>\n",
       "      <td>900.416667</td>\n",
       "      <td>4226.875000</td>\n",
       "      <td>0.607735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.012917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.777550</td>\n",
       "      <td>192.976761</td>\n",
       "      <td>25200.000000</td>\n",
       "      <td>7919.166667</td>\n",
       "      <td>5687.583333</td>\n",
       "      <td>936.125000</td>\n",
       "      <td>4772.708333</td>\n",
       "      <td>0.550615</td>\n",
       "      <td>0.607735</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.415000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.578989</td>\n",
       "      <td>145.680145</td>\n",
       "      <td>22528.138672</td>\n",
       "      <td>6796.166667</td>\n",
       "      <td>5695.333333</td>\n",
       "      <td>885.875000</td>\n",
       "      <td>5641.333333</td>\n",
       "      <td>0.292413</td>\n",
       "      <td>0.550615</td>\n",
       "      <td>0.607735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.783750</td>\n",
       "      <td>5.6</td>\n",
       "      <td>19.376562</td>\n",
       "      <td>158.291138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6761.166667</td>\n",
       "      <td>5699.083333</td>\n",
       "      <td>773.583333</td>\n",
       "      <td>6008.166667</td>\n",
       "      <td>0.422040</td>\n",
       "      <td>0.292413</td>\n",
       "      <td>0.550615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.665035</td>\n",
       "      <td>285.209167</td>\n",
       "      <td>13441.726562</td>\n",
       "      <td>8010.666667</td>\n",
       "      <td>5821.875000</td>\n",
       "      <td>843.083333</td>\n",
       "      <td>8072.083333</td>\n",
       "      <td>0.735706</td>\n",
       "      <td>0.270241</td>\n",
       "      <td>0.273672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>1.227500</td>\n",
       "      <td>5.2</td>\n",
       "      <td>22.195539</td>\n",
       "      <td>187.205170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8695.333333</td>\n",
       "      <td>5818.708333</td>\n",
       "      <td>722.333333</td>\n",
       "      <td>7440.625000</td>\n",
       "      <td>0.384965</td>\n",
       "      <td>0.735706</td>\n",
       "      <td>0.270241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>4.194167</td>\n",
       "      <td>2.1</td>\n",
       "      <td>24.069572</td>\n",
       "      <td>236.131195</td>\n",
       "      <td>1470.378784</td>\n",
       "      <td>8381.250000</td>\n",
       "      <td>5819.791667</td>\n",
       "      <td>530.291667</td>\n",
       "      <td>6671.708333</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.384965</td>\n",
       "      <td>0.735706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17.748037</td>\n",
       "      <td>283.297974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8964.833333</td>\n",
       "      <td>5823.208333</td>\n",
       "      <td>635.375000</td>\n",
       "      <td>7656.208333</td>\n",
       "      <td>0.324242</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.384965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>0.015417</td>\n",
       "      <td>10.5</td>\n",
       "      <td>18.719999</td>\n",
       "      <td>3.529286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8191.875000</td>\n",
       "      <td>5821.750000</td>\n",
       "      <td>515.916667</td>\n",
       "      <td>6341.791667</td>\n",
       "      <td>0.075346</td>\n",
       "      <td>0.324242</td>\n",
       "      <td>0.230300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>782 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     temperature_2m_mean  precipitation_sum  wind_speed_10m_max  \\\n",
       "0               8.792083                1.2           13.202726   \n",
       "1               9.612916                0.9           13.276144   \n",
       "2               8.012917                0.0           14.777550   \n",
       "3               8.415000                0.0           21.578989   \n",
       "4               7.783750                5.6           19.376562   \n",
       "..                   ...                ...                 ...   \n",
       "777             0.998333                0.0           23.665035   \n",
       "778             1.227500                5.2           22.195539   \n",
       "779             4.194167                2.1           24.069572   \n",
       "780             0.140000                0.2           17.748037   \n",
       "781             0.015417               10.5           18.719999   \n",
       "\n",
       "     wind_direction_10m_dominant  sunshine_duration     hydro_mw   nuclear_mw  \\\n",
       "0                     210.351074           0.000000  8805.291667  5699.208333   \n",
       "1                     187.686081       19597.978516  7981.458333  5689.541667   \n",
       "2                     192.976761       25200.000000  7919.166667  5687.583333   \n",
       "3                     145.680145       22528.138672  6796.166667  5695.333333   \n",
       "4                     158.291138           0.000000  6761.166667  5699.083333   \n",
       "..                           ...                ...          ...          ...   \n",
       "777                   285.209167       13441.726562  8010.666667  5821.875000   \n",
       "778                   187.205170           0.000000  8695.333333  5818.708333   \n",
       "779                   236.131195        1470.378784  8381.250000  5819.791667   \n",
       "780                   283.297974           0.000000  8964.833333  5823.208333   \n",
       "781                     3.529286           0.000000  8191.875000  5821.750000   \n",
       "\n",
       "       other_mw      wind_mw  price_lag_1  price_lag_2  price_lag_3  \n",
       "0    897.958333  2831.708333          NaN          NaN          NaN  \n",
       "1    900.416667  4226.875000     0.607735          NaN          NaN  \n",
       "2    936.125000  4772.708333     0.550615     0.607735          NaN  \n",
       "3    885.875000  5641.333333     0.292413     0.550615     0.607735  \n",
       "4    773.583333  6008.166667     0.422040     0.292413     0.550615  \n",
       "..          ...          ...          ...          ...          ...  \n",
       "777  843.083333  8072.083333     0.735706     0.270241     0.273672  \n",
       "778  722.333333  7440.625000     0.384965     0.735706     0.270241  \n",
       "779  530.291667  6671.708333     0.230300     0.384965     0.735706  \n",
       "780  635.375000  7656.208333     0.324242     0.230300     0.384965  \n",
       "781  515.916667  6341.791667     0.075346     0.324242     0.230300  \n",
       "\n",
       "[782 rows x 12 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['price_lag_1'] = target.shift(1).values\n",
    "features['price_lag_2'] = target.shift(2).values\n",
    "features['price_lag_3'] = target.shift(3).values\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = torch.from_numpy(normalized_features_df.values) # For LSTM\n",
    "X = torch.from_numpy(features.values) # For XGBoost\n",
    "y = torch.from_numpy(target.values)\n",
    "\n",
    "train_num = int(0.80 * X.shape[0])\n",
    "X_train = X[:train_num]\n",
    "X_test = X[train_num:]\n",
    "y_train = y[:train_num]\n",
    "y_test = y[train_num:]\n",
    "\n",
    "# val_num = int(0.2 * train_num)  \n",
    "# X_val = X_train[-val_num:]\n",
    "# y_val = y_train[-val_num:]\n",
    "# X_train = X_train[:-val_num]\n",
    "# y_train = y_train[:-val_num]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([663, 9])"
      ]
     },
     "execution_count": 1134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = [\n",
    "        \"temperature_2m_mean\", \"precipitation_sum\", \"wind_speed_10m_max\",\n",
    "        \"wind_direction_10m_dominant\", \"sunshine_duration\",\n",
    "        \"Hydro Water Reservoir\", \"Nuclear\", \"Other\", \"Wind Onshore\", \n",
    "]\n",
    "input_size = len(input_features)\n",
    "# model = nn.EnergyPricePredictorLSTM(input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, X, y, seq_length):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) // self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_seq = self.X[idx:idx + self.seq_length]\n",
    "        y_hist = self.y[idx:idx + self.seq_length].reshape(-1, 1) \n",
    "        x_combined = torch.tensor(np.hstack((x_seq, y_hist)), dtype=torch.float32)\n",
    "        y_target = torch.tensor(self.y[idx + self.seq_length], dtype=torch.float32)\n",
    "        return x_combined, y_target\n",
    "\n",
    "\n",
    "        # y_seq = self.y[idx:idx + self.seq_length].unsqueeze(-1)\n",
    "        # y_target = self.y[idx + self.seq_length]\n",
    "        # return torch.tensor(y_seq, dtype=torch.float32), torch.tensor(y_target, dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 3\n",
    "input_size = 10\n",
    "batch_size = 16\n",
    "train_dataset = SequenceDataset(X_train, y_train, seq_length)\n",
    "test_dataset = SequenceDataset(X_test, y_test, seq_length)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# val_dataset = SequenceDataset(X_val, y_val, seq_length)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 10])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 3, 10])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(train_loader):\n",
    "    print(X.size())\n",
    "    print(y.size())\n",
    "    break\n",
    "\n",
    "for i, (X, y) in enumerate(test_loader):\n",
    "    print(X.size())\n",
    "    print(y.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 16        \n",
    "num_layers = 2     \n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 2.3706\n",
      "Epoch 26, Training Loss: 1.9691\n",
      "Epoch 51, Training Loss: 1.2605\n",
      "Epoch 76, Training Loss: 1.0397\n",
      "Epoch 101, Training Loss: 0.8215\n",
      "Epoch 126, Training Loss: 0.7150\n",
      "Epoch 151, Training Loss: 0.5225\n",
      "Epoch 176, Training Loss: 0.4641\n",
      "Epoch 201, Training Loss: 0.4762\n",
      "Epoch 226, Training Loss: 0.4390\n",
      "Epoch 251, Training Loss: 0.3829\n",
      "Epoch 276, Training Loss: 0.4037\n",
      "Epoch 301, Training Loss: 0.2715\n",
      "Epoch 326, Training Loss: 0.3298\n",
      "Epoch 351, Training Loss: 0.3066\n",
      "Epoch 376, Training Loss: 0.3095\n",
      "Epoch 401, Training Loss: 0.3111\n",
      "Epoch 426, Training Loss: 0.3111\n",
      "Epoch 451, Training Loss: 0.2945\n",
      "Epoch 476, Training Loss: 0.2328\n",
      "Epoch 501, Training Loss: 0.2554\n",
      "Epoch 526, Training Loss: 0.3115\n",
      "Epoch 551, Training Loss: 0.3030\n",
      "Epoch 576, Training Loss: 0.2928\n",
      "Epoch 601, Training Loss: 0.2201\n",
      "Epoch 626, Training Loss: 0.2258\n",
      "Epoch 651, Training Loss: 0.2798\n",
      "Epoch 676, Training Loss: 0.2145\n",
      "Epoch 701, Training Loss: 0.2457\n",
      "Epoch 726, Training Loss: 0.2237\n",
      "Epoch 751, Training Loss: 0.1828\n",
      "Epoch 776, Training Loss: 0.1896\n",
      "Epoch 801, Training Loss: 0.2529\n",
      "Epoch 826, Training Loss: 0.2434\n",
      "Epoch 851, Training Loss: 0.2182\n",
      "Epoch 876, Training Loss: 0.2245\n",
      "Epoch 901, Training Loss: 0.2281\n",
      "Epoch 926, Training Loss: 0.2148\n",
      "Epoch 951, Training Loss: 0.1730\n",
      "Epoch 976, Training Loss: 0.1680\n",
      "Epoch 1001, Training Loss: 0.2151\n",
      "Epoch 1026, Training Loss: 0.2186\n",
      "Epoch 1051, Training Loss: 0.1852\n",
      "Epoch 1076, Training Loss: 0.2248\n",
      "Epoch 1101, Training Loss: 0.2034\n",
      "Epoch 1126, Training Loss: 0.1959\n",
      "Epoch 1151, Training Loss: 0.1791\n",
      "Epoch 1176, Training Loss: 0.2141\n",
      "Epoch 1201, Training Loss: 0.1691\n",
      "Epoch 1226, Training Loss: 0.1802\n",
      "Epoch 1251, Training Loss: 0.1625\n",
      "Epoch 1276, Training Loss: 0.1495\n",
      "Epoch 1301, Training Loss: 0.1736\n",
      "Epoch 1326, Training Loss: 0.1487\n",
      "Epoch 1351, Training Loss: 0.1937\n",
      "Epoch 1376, Training Loss: 0.1409\n",
      "Epoch 1401, Training Loss: 0.1301\n",
      "Epoch 1426, Training Loss: 0.1642\n",
      "Epoch 1451, Training Loss: 0.1697\n",
      "Epoch 1476, Training Loss: 0.2028\n",
      "Epoch 1501, Training Loss: 0.1635\n",
      "Epoch 1526, Training Loss: 0.1767\n",
      "Epoch 1551, Training Loss: 0.1454\n",
      "Epoch 1576, Training Loss: 0.1669\n",
      "Epoch 1601, Training Loss: 0.1933\n",
      "Epoch 1626, Training Loss: 0.1355\n",
      "Epoch 1651, Training Loss: 0.1532\n",
      "Epoch 1676, Training Loss: 0.1563\n",
      "Epoch 1701, Training Loss: 0.1665\n",
      "Epoch 1726, Training Loss: 0.1704\n",
      "Epoch 1751, Training Loss: 0.1716\n",
      "Epoch 1776, Training Loss: 0.1634\n",
      "Epoch 1801, Training Loss: 0.1486\n",
      "Epoch 1826, Training Loss: 0.1633\n",
      "Epoch 1851, Training Loss: 0.1532\n",
      "Epoch 1876, Training Loss: 0.1856\n",
      "Epoch 1901, Training Loss: 0.1719\n",
      "Epoch 1926, Training Loss: 0.1506\n",
      "Epoch 1951, Training Loss: 0.1537\n",
      "Epoch 1976, Training Loss: 0.1664\n",
      "Epoch 2001, Training Loss: 0.1269\n",
      "Epoch 2026, Training Loss: 0.1453\n",
      "Epoch 2051, Training Loss: 0.1263\n",
      "Epoch 2076, Training Loss: 0.1633\n",
      "Epoch 2101, Training Loss: 0.1537\n",
      "Epoch 2126, Training Loss: 0.1179\n",
      "Epoch 2151, Training Loss: 0.1246\n",
      "Epoch 2176, Training Loss: 0.1286\n",
      "Epoch 2201, Training Loss: 0.1427\n",
      "Epoch 2226, Training Loss: 0.1386\n",
      "Epoch 2251, Training Loss: 0.1467\n",
      "Epoch 2276, Training Loss: 0.1516\n",
      "Epoch 2301, Training Loss: 0.1246\n",
      "Epoch 2326, Training Loss: 0.1317\n",
      "Epoch 2351, Training Loss: 0.1452\n",
      "Epoch 2376, Training Loss: 0.1264\n",
      "Epoch 2401, Training Loss: 0.1267\n",
      "Epoch 2426, Training Loss: 0.1293\n",
      "Epoch 2451, Training Loss: 0.1363\n",
      "Epoch 2476, Training Loss: 0.1181\n",
      "Epoch 2501, Training Loss: 0.1333\n",
      "Epoch 2526, Training Loss: 0.1227\n",
      "Epoch 2551, Training Loss: 0.1497\n",
      "Epoch 2576, Training Loss: 0.1263\n",
      "Epoch 2601, Training Loss: 0.1463\n",
      "Epoch 2626, Training Loss: 0.1270\n",
      "Epoch 2651, Training Loss: 0.1229\n",
      "Epoch 2676, Training Loss: 0.1115\n",
      "Epoch 2701, Training Loss: 0.1316\n",
      "Epoch 2726, Training Loss: 0.1181\n",
      "Epoch 2751, Training Loss: 0.1326\n",
      "Epoch 2776, Training Loss: 0.1532\n",
      "Epoch 2801, Training Loss: 0.1161\n",
      "Epoch 2826, Training Loss: 0.1239\n",
      "Epoch 2851, Training Loss: 0.1017\n",
      "Epoch 2876, Training Loss: 0.1365\n",
      "Epoch 2901, Training Loss: 0.1415\n",
      "Epoch 2926, Training Loss: 0.1284\n",
      "Epoch 2951, Training Loss: 0.0966\n",
      "Epoch 2976, Training Loss: 0.1240\n",
      "Epoch 3001, Training Loss: 0.1249\n",
      "Epoch 3026, Training Loss: 0.1357\n",
      "Epoch 3051, Training Loss: 0.1116\n",
      "Epoch 3076, Training Loss: 0.1157\n",
      "Epoch 3101, Training Loss: 0.1370\n",
      "Epoch 3126, Training Loss: 0.1322\n",
      "Epoch 3151, Training Loss: 0.1412\n",
      "Epoch 3176, Training Loss: 0.1048\n",
      "Epoch 3201, Training Loss: 0.1104\n",
      "Epoch 3226, Training Loss: 0.1390\n",
      "Epoch 3251, Training Loss: 0.1519\n",
      "Epoch 3276, Training Loss: 0.1147\n",
      "Epoch 3301, Training Loss: 0.1250\n",
      "Epoch 3326, Training Loss: 0.1217\n",
      "Epoch 3351, Training Loss: 0.1148\n",
      "Epoch 3376, Training Loss: 0.1208\n",
      "Epoch 3401, Training Loss: 0.1317\n",
      "Epoch 3426, Training Loss: 0.1085\n",
      "Epoch 3451, Training Loss: 0.1239\n",
      "Epoch 3476, Training Loss: 0.0995\n",
      "Epoch 3501, Training Loss: 0.0954\n",
      "Epoch 3526, Training Loss: 0.1559\n",
      "Epoch 3551, Training Loss: 0.1294\n",
      "Epoch 3576, Training Loss: 0.1241\n",
      "Epoch 3601, Training Loss: 0.1141\n",
      "Epoch 3626, Training Loss: 0.1204\n",
      "Epoch 3651, Training Loss: 0.0963\n",
      "Epoch 3676, Training Loss: 0.1274\n",
      "Epoch 3701, Training Loss: 0.1111\n",
      "Epoch 3726, Training Loss: 0.1275\n",
      "Epoch 3751, Training Loss: 0.1072\n",
      "Epoch 3776, Training Loss: 0.0961\n",
      "Epoch 3801, Training Loss: 0.0870\n",
      "Epoch 3826, Training Loss: 0.1374\n",
      "Epoch 3851, Training Loss: 0.1186\n",
      "Epoch 3876, Training Loss: 0.0903\n",
      "Epoch 3901, Training Loss: 0.0820\n",
      "Epoch 3926, Training Loss: 0.1079\n",
      "Epoch 3951, Training Loss: 0.1097\n",
      "Epoch 3976, Training Loss: 0.1064\n",
      "Epoch 4001, Training Loss: 0.1082\n",
      "Epoch 4026, Training Loss: 0.0937\n",
      "Epoch 4051, Training Loss: 0.1408\n",
      "Epoch 4076, Training Loss: 0.1070\n",
      "Epoch 4101, Training Loss: 0.1045\n",
      "Epoch 4126, Training Loss: 0.1116\n",
      "Epoch 4151, Training Loss: 0.1058\n",
      "Epoch 4176, Training Loss: 0.1254\n",
      "Epoch 4201, Training Loss: 0.1055\n",
      "Epoch 4226, Training Loss: 0.1086\n",
      "Epoch 4251, Training Loss: 0.1137\n",
      "Epoch 4276, Training Loss: 0.1420\n",
      "Epoch 4301, Training Loss: 0.1012\n",
      "Epoch 4326, Training Loss: 0.1209\n",
      "Epoch 4351, Training Loss: 0.1119\n",
      "Epoch 4376, Training Loss: 0.1043\n",
      "Epoch 4401, Training Loss: 0.0998\n",
      "Epoch 4426, Training Loss: 0.0943\n",
      "Epoch 4451, Training Loss: 0.1218\n",
      "Epoch 4476, Training Loss: 0.0967\n",
      "Epoch 4501, Training Loss: 0.1501\n",
      "Epoch 4526, Training Loss: 0.1058\n",
      "Epoch 4551, Training Loss: 0.0806\n",
      "Epoch 4576, Training Loss: 0.0917\n",
      "Epoch 4601, Training Loss: 0.1019\n",
      "Epoch 4626, Training Loss: 0.0896\n",
      "Epoch 4651, Training Loss: 0.0940\n",
      "Epoch 4676, Training Loss: 0.1298\n",
      "Epoch 4701, Training Loss: 0.0949\n",
      "Epoch 4726, Training Loss: 0.0858\n",
      "Epoch 4751, Training Loss: 0.1006\n",
      "Epoch 4776, Training Loss: 0.1091\n",
      "Epoch 4801, Training Loss: 0.1359\n",
      "Epoch 4826, Training Loss: 0.1071\n",
      "Epoch 4851, Training Loss: 0.1074\n",
      "Epoch 4876, Training Loss: 0.1031\n",
      "Epoch 4901, Training Loss: 0.1136\n",
      "Epoch 4926, Training Loss: 0.1155\n",
      "Epoch 4951, Training Loss: 0.1220\n",
      "Epoch 4976, Training Loss: 0.0927\n",
      "MSE: 0.06738361042937509\n",
      "R squared: -1.6750771549581667\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "class PriceLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(PriceLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)  \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)  \n",
    "        out, _ = self.lstm(x, (h0, c0))  \n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "\n",
    "num_epochs = 5000\n",
    "model = PriceLSTM(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "train_loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred.squeeze(), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "\n",
    "    train_loss_list.append(train_loss/len(train_loader))\n",
    "    if epoch % 25 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Training Loss: {train_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # if epoch % 20 == 0:\n",
    "    #     model.eval()\n",
    "\n",
    "    #     val_loss = 0\n",
    "    #     with torch.no_grad():\n",
    "    #         for X_batch, y_batch in val_loader:\n",
    "    #             y_pred = model(X_batch)\n",
    "    #             val_loss += loss.item()\n",
    "        \n",
    "    #     print(f\"Epoch {epoch+1}, Training Loss: {train_loss/len(train_loader):.4f}, Validation Loss: {val_loss/len(val_loader)}\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "y_preds = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        y_pred = model(X_batch)\n",
    "        y_preds += y_pred.squeeze().tolist()\n",
    "        y_true += y_batch.tolist()\n",
    "\n",
    "mse = mean_squared_error(y_true, y_preds)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "r2 = r2_score(y_true, y_preds)\n",
    "print(\"R squared:\", r2)\n",
    "# 0.15 0.12 0.24 / 3x64 \n",
    "#      0.13          / 3x128\n",
    "#      0.16          / 3x32\n",
    "#      0.10   0.19    0.35 0.274  / 2x64\n",
    "# 0.102 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Variance: 0.012120836186714877\n"
     ]
    }
   ],
   "source": [
    "target_variance = np.var(y_true)\n",
    "print(\"Target Variance:\", target_variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Mean: 0.11867289241546622\n"
     ]
    }
   ],
   "source": [
    "target_mean = np.mean(y_true)\n",
    "print(\"Target Mean:\", target_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32315653562545776, 0.25238165259361267, 0.25038230419158936, 0.22440654039382935, 0.28922802209854126, 0.36193370819091797, 0.19421449303627014, 0.2526513338088989, 0.21887004375457764, 0.14466416835784912, 0.12356337904930115, 0.10380619019269943, 0.1399623602628708, 0.2858304977416992, 0.5071783661842346, 0.3986421823501587, 0.47549405694007874, 0.20019099116325378, 0.2068873792886734, 0.1932094246149063, 0.19209063053131104, 0.1959439516067505, 0.08877623826265335, 0.09596601128578186, 0.11146038770675659, 0.17437508702278137, 0.15514889359474182, 0.20192950963974, 0.17841124534606934, 0.3363396227359772, 0.13258112967014313, 0.16613391041755676, 0.19559583067893982, 0.29330918192863464, 0.22525247931480408, 0.4076455235481262, 0.4698227643966675, 0.4820707142353058, 0.2088499367237091]\n",
      "[0.04659541696310043, 0.024965833872556686, 0.014926666393876076, 0.10545500367879868, 0.46143290400505066, 0.28074583411216736, 0.20934750139713287, 0.2059720903635025, 0.11346250027418137, 0.07605333626270294, 0.04117708280682564, 0.015957916155457497, 0.007927916944026947, 0.1382116675376892, 0.07393166422843933, 0.2038566619157791, 0.07044333219528198, 0.09565208107233047, 0.4261316657066345, 0.3946758210659027, 0.2826724946498871, 0.1870425045490265, 0.17611292004585266, 0.09169375151395798, 0.17712458968162537, 0.21642166376113892, 0.2036779224872589, 0.08752249926328659, 0.13366208970546722, 0.0705450028181076, 0.06853000074625015, 0.07089708000421524, 0.24656875431537628, 0.33079665899276733, 0.6155470609664917, 0.5082803964614868, 0.6039012670516968, 0.30188000202178955, 0.28286126255989075]\n"
     ]
    }
   ],
   "source": [
    "print(y_preds)\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07444219519523172\n",
      "R squared: 0.5720467092865618\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=1000, learning_rate=0.01)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R squared:\", r2)\n",
    "\n",
    "eval_dict = { \n",
    "    \"MSE\": str(mse),\n",
    "    \"R squared\": str(r2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16029027104377747, 0.14934468269348145, 0.23059038817882538, 0.2925604283809662, 0.23977287113666534, 0.254116028547287, 0.24189607799053192, 0.29992276430130005, 0.2171967774629593, 0.20159846544265747, 0.1929854303598404, 0.2896548807621002, 0.4172971546649933, 0.17731235921382904, 0.29140400886535645, 0.324682354927063, 0.3757933974266052, 0.13666345179080963, 0.4034905433654785, 0.21132895350456238, 0.21926088631153107, 0.08550919592380524, 0.15067371726036072, 0.16247326135635376, 0.260773241519928, 0.2945998013019562, 0.23177891969680786, 0.21089808642864227, 0.10155300796031952, 0.10985223203897476, 0.18600359559059143, 0.1226571798324585, 0.16855183243751526, 0.14357145130634308, 0.07849326729774475, 0.13393817842006683, 0.039084888994693756, 0.17184443771839142, 0.10186558216810226, 0.16711173951625824, 0.1531064510345459, 0.16869014501571655, 0.09945947676897049, 0.08234670758247375, 0.21550244092941284, 0.14611244201660156, 0.34786415100097656, 0.2542768120765686, 0.16390009224414825, 0.2004155069589615, 0.17029538750648499, 0.2880319654941559, 0.19126152992248535, -0.00023231480736285448, 0.07783056795597076, 0.11409085988998413, 0.061150405555963516, 0.2591933310031891, 0.13955219089984894, 0.2943054437637329, 0.593445360660553, 0.28662803769111633, 0.3217066526412964, 0.1832513064146042, 0.26284220814704895, 0.22280724346637726, 0.2035897970199585, 0.10429509729146957, 0.1314575970172882, 0.09794943779706955, 0.20661096274852753, 0.18177121877670288, 0.1346680074930191, 0.36684706807136536, 0.17606894671916962, 0.2961720824241638, 0.6453938484191895, 0.31350526213645935, 0.43798497319221497, 0.26692670583724976, 0.2686986029148102, 0.4933501183986664, 0.26140955090522766, 0.20609797537326813, 0.23326949775218964, 0.04821045324206352, 0.12445258349180222, 0.06482023745775223, 0.44180822372436523, 0.5515602231025696, 0.3627321422100067, 0.08781028538942337, 0.06572021543979645, 0.05759815126657486, 0.06459780037403107, 0.04033367335796356, 0.09669409692287445, 0.06697911024093628, 0.33811426162719727, 0.07361583411693573, 0.4716406464576721, 0.10705692321062088, 0.33053523302078247, 0.45943090319633484, 0.278678834438324, 0.12200502306222916, 0.1255192905664444, 0.4404642879962921, 0.41825518012046814, 0.8016453385353088, 0.38092750310897827, 0.4168030917644501, 0.5444853901863098, 0.5455698370933533, 0.5755189061164856, 0.5781259536743164, 0.7229524850845337, 1.0118879079818726, 0.5808700919151306, 0.60540372133255, 0.3456912338733673, 0.10463219881057739, 0.3680683672428131, 0.6820486783981323, 1.168671727180481, 0.7401761412620544, 0.7678041458129883, 0.9357110857963562, 0.6086097955703735, 0.14815008640289307, 0.18997178971767426, 0.39914509654045105, 0.9047791361808777, 1.0549132823944092, 0.6957623958587646, 0.2501191794872284, 0.30484649538993835, 0.34038281440734863, 1.192164659500122, 1.0041409730911255, 0.5170063376426697, 0.4326530396938324, 0.535580039024353, 0.5499064326286316, 0.6657763123512268, 1.151601791381836, 2.0082061290740967, 1.9307613372802734, 1.1540712118148804, 0.46417537331581116, 0.4089675843715668, 0.3699913024902344, 0.637881875038147, 0.402523934841156, 0.22874869406223297, 0.46571412682533264, 0.30820804834365845]\n",
      "[0.2022375, 0.18591625, 0.1883979166666667, 0.2627529166666666, 0.2527345833333333, 0.2436029166666666, 0.2651425, 0.2322075, 0.2408766666666666, 0.0353704166666666, 0.0461104166666666, 0.152695, 0.0861070833333333, 0.0773445833333333, 0.1669195833333333, 0.1995808333333333, 0.1972558333333333, 0.2884691666666666, 0.2562970833333333, 0.1921279166666666, 0.0901220833333333, 0.0490070833333333, -0.07195875, -0.0789816666666666, 0.1379041666666666, 0.23176125, 0.2023916666666666, 0.0999179166666666, 0.0913195833333333, 0.1288079166666666, 0.1078095833333333, 0.0930245833333333, 0.0629233333333333, 0.0305816666666666, 0.0549116666666666, 0.0064558333333333, -0.0598720833333333, -0.05232875, -0.0054229166666666, 0.02532125, 0.0392820833333333, 0.0465954166666666, 0.0249658333333333, 0.0149266666666666, 0.105455, 0.4614329166666667, 0.2807458333333333, 0.2093475, 0.2059720833333333, 0.1134625, 0.0760533333333333, 0.0411770833333333, 0.0159579166666666, 0.0079279166666666, 0.1382116666666666, 0.0739316666666666, 0.2038566666666666, 0.0704433333333333, 0.0956520833333333, 0.4261316666666666, 0.3946758333333333, 0.2826725, 0.1870425, 0.1761129166666666, 0.09169375, 0.1771245833333333, 0.2164216666666666, 0.2036779166666666, 0.0875225, 0.1336620833333333, 0.070545, 0.06853, 0.0708970833333333, 0.24656875, 0.3307966666666667, 0.6155470833333333, 0.5082804166666667, 0.60390125, 0.30188, 0.28286125, 0.4417525, 0.3312783333333333, 0.0908958333333333, 0.1728558333333333, 0.0735429166666666, 0.1113708333333333, 0.1382041666666666, 0.4378441666666666, 0.4962695833333333, 0.1489166666666666, 0.0223829166666666, 0.1123458333333333, 0.0548345833333333, 0.01172375, -0.0112924999999999, 0.036265, 0.0057820833333333, 0.2842366666666667, 0.225065, 0.5002495833333334, -0.0044192, 0.1074833333333333, 0.483795, 0.0918366666666666, 0.1311616666666666, 0.0324504166666666, 0.09575, 0.05667, 0.9974720833333334, 0.90026875, 0.9004404166666666, 0.76818625, 0.39891875, 0.7560875, 0.9373220833333334, 1.0894370833333331, 1.3467133333333334, 0.6673691666666667, 0.4021591666666666, 0.1950154166666666, 0.01695, 0.1841925, 0.92321375, 1.395010833333333, 0.9178320833333332, 1.08638125, 1.3136391666666667, 0.63119, 0.0515491666666666, 0.1462670833333333, 0.2763516666666666, 1.090235, 1.1072841666666666, 1.0783116666666668, 0.3049370833333333, 0.2232491666666666, 0.2585208333333333, 1.0650804166666668, 1.65598625, 0.6936058333333333, 0.4553525, 0.5208804166666666, 0.6291208333333334, 0.7726504166666667, 0.9673645833333334, 2.277274583333333, 2.44152, 1.2624733333333331, 0.2317570833333333, 0.2736725, 0.2702408333333333, 0.7357058333333333, 0.384965, 0.2303004166666666, 0.3242425, 0.07534625, 0.9258479166666667]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.tolist())\n",
    "print(y_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload model to Hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"price_prediction_model\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.save_model(model_dir + \"/model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06f704bad6f41ed888ba94eeb534f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1806901114624384ad4e933240676bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/3968394 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d2d8d8f4ff4636980656762d719967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/20 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecca83e07234ee0afea8e8a287e0cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/1162 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/1164449/models/price_prediction_model/4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'price_prediction_model', version: 4)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "input_schema = Schema(features)\n",
    "output_schema = Schema(target)\n",
    "\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "mr = proj.get_model_registry()\n",
    "\n",
    "price_prediction_model = mr.python.create_model(\n",
    "    name=\"price_prediction_model\", \n",
    "    metrics=eval_dict,\n",
    "    model_schema=model_schema,\n",
    "    input_example=target.sample().values, \n",
    "    description=\"Electricity Price Predicition Model\",\n",
    ")\n",
    "\n",
    "price_prediction_model.save(model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
